{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lP6JLo1tGNBg"
   },
   "source": [
    "# BIC- PSO ANN Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWZyYmS_UE_L"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxkJoQBkUIHC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Import PySwarms as instructed by pyswarms webpage\n",
    "import pyswarms as ps\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1E0Q3aoKUCRX"
   },
   "source": [
    "## 1. Implement a multi-layer ANN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "#### Importing the dataset (Churn Modelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXUkhkMfU4wq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [806 'France' 'Male' ... 1 1 142838.64]\n",
      " [757 'Germany' 'Male' ... 1 1 127059.04]\n",
      " [570 'France' 'Female' ... 0 1 116503.92]]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "#### Encoding gender label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "#### Encoding geography label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zfEzkRVXIwF"
   },
   "source": [
    "### Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvdeScabXtlB"
   },
   "source": [
    "#### Initialising the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dtrScHxXQox"
   },
   "outputs": [],
   "source": [
    "#ANN architecture\n",
    "n_inputs = 12\n",
    "n_hidden = 20\n",
    "n_classes = 2\n",
    "\n",
    "num_samples = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add weight calculation\n",
    "def logits_f(p):\n",
    "\n",
    "    W1 = p[0:240].reshape((n_inputs,n_hidden))\n",
    "    b1 = p[240:260].reshape((n_hidden,))\n",
    "    W2 = p[260:300].reshape((n_hidden,n_classes))\n",
    "    b2 = p[300:302].reshape((n_classes,))\n",
    "\n",
    "# Forward propagation\n",
    "    z1 = X.dot(W1) + b1 \n",
    "    a1 = np.tanh(z1.astype(float))    \n",
    "    logits = a1.dot(W2) + b2 \n",
    "    return logits         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_prop(params):\n",
    "\n",
    "    logits = logits_f(params)\n",
    "\n",
    "# Softmax\n",
    "    scores = np.exp(logits)\n",
    "    probs = scores / np.sum(scores, axis=1, keepdims=True)\n",
    "\n",
    "    corect_logprobs = -np.log(probs[range(num_samples), y])\n",
    "    loss = np.sum(corect_logprobs) / num_samples\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    n_particles = x.shape[0]\n",
    "    j = [f_prop(x[i]) for i in range(n_particles)]\n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSO Oprimisation with pyswarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 13:55:58,718 - pyswarms.single.local_best - INFO - Optimize for 500 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9, 'k': 2, 'p': 2}\n",
      "pyswarms.single.local_best: 100%|██████████|500/500, best_cost=0.486\n",
      "2020-11-23 13:57:48,274 - pyswarms.single.local_best - INFO - Optimization finished | best cost: 0.4860537795517748, best pos: [-0.38948862  0.62058464  0.54049379  0.70351343 -0.17398251  0.53269784\n",
      "  1.00248901  0.07674998  0.52169167  0.00751177  0.30222026  0.69665302\n",
      "  0.78148092  0.83307309  0.7220176  -0.08038299 -0.90947785 -0.85563994\n",
      " -0.34480684  0.068742    0.1108463  -0.27294563 -0.45072356  0.33447059\n",
      "  0.19101363 -0.07640913  0.04073217  0.54610771 -0.0696881  -0.12047354\n",
      "  0.10423682  0.19295416  0.27573802  0.81831682  0.35326656  0.105834\n",
      "  0.12184845 -0.50624567  0.53831136 -0.08800036  0.15156822 -0.07253716\n",
      "  0.18487573 -0.0443812   0.20308999  0.6708069   0.54149348  0.31425247\n",
      " -0.54251423  0.28938341 -0.35680026  0.53575897 -0.10948748  0.55132346\n",
      " -0.0026252   0.31975046 -0.06290501  0.1010092   0.29454566  0.70295368\n",
      " -0.22042309  0.43705592 -0.00673332 -0.7706372   0.12047002  0.5378674\n",
      "  0.1936652   0.08636711  0.58302855  0.66606571 -0.12718042  0.48766787\n",
      " -0.82702028 -0.0988352   0.20742288  0.80011881  0.158237    0.36283892\n",
      " -0.31473882 -0.00886987  0.45669847  0.8261494   0.06249754  0.15180187\n",
      " -0.69432516  0.68885211 -0.49013711  0.45162593  0.10939434 -0.14589164\n",
      "  0.55841568 -0.59071152  0.93535605  0.11309488  1.21044425  0.05289907\n",
      " -0.00307733 -0.3305403   0.19670177  0.40249908  0.39334695 -0.07368651\n",
      " -0.17355608 -0.10514613  0.36493301 -0.2069654   0.5379582   0.90968138\n",
      "  0.40555238 -0.87582385  0.3237201   0.08887351  0.15151546  0.10324686\n",
      " -0.19329634  0.59752468  0.14079207  0.72560887  0.45005784 -0.02205541\n",
      "  0.93374001  0.41936825 -0.77204099  0.69881928  0.74039271  0.17760539\n",
      "  0.77609617  0.4324847   0.764817    0.00796202  0.33595987  0.26742495\n",
      "  0.4894726   0.38021635  0.16520153  0.24418797 -0.16379778  0.32700452\n",
      "  0.3293872   0.27455244  0.27671406  1.10707395 -0.017407    1.02043738\n",
      " -0.66653934  0.0453296   0.63467915  0.99618529 -0.26252048  0.78302909\n",
      "  0.66087205  0.32574708  0.1568022  -0.03925042  0.78327631  0.3453889\n",
      " -0.04109606  0.58956597  0.49670892  0.39333973 -0.15721418  0.36458424\n",
      "  0.23968984 -0.01033956  0.72698861  0.27023745  0.76669272  0.83648767\n",
      "  0.25245272  0.25353739 -0.64782518 -0.33253193  0.74796956  0.85705051\n",
      "  0.51059293 -0.0094872   0.42060676  0.77108419 -0.37274208  0.72536131\n",
      "  0.27314076 -0.92544878  0.48827898 -0.52318456  0.07206067  0.06392342\n",
      "  0.44885759  0.68213257  0.53376952  0.5907441   0.66548537  0.61011676\n",
      "  0.60930973  0.44122986  0.65693955 -0.54057407  0.28940757 -0.20662657\n",
      "  0.04696981  0.24578295 -0.16063462 -0.16878174  0.24493258  0.16349516\n",
      "  0.23309335  0.42213611 -0.53263374  0.12125667 -0.59987584  0.04501251\n",
      " -0.47488139  0.89463515  0.80599232  0.8972825  -0.39541171  0.79122372\n",
      "  0.05095123 -0.14184859  0.35310008  0.02827074  0.49697298  0.69633929\n",
      "  0.07172253  0.4370774  -0.73700366 -0.16100504 -0.17727876  0.22293476\n",
      " -0.32088199 -0.17341735  0.7758063   0.48354488  0.83258581 -0.8833206\n",
      " -0.46770401 -0.32959993  0.10441505 -0.01669664  0.04987569  0.52649022\n",
      "  0.56393533  0.16585895  0.36455629  0.59934267  0.71971908 -0.96439673\n",
      "  0.07736847  0.61641578  0.269741    0.03480599  0.50604333  0.93534708\n",
      "  0.76261483 -0.44621782  0.72145436 -0.18015663  0.47733791  1.16764294\n",
      "  0.17443813  0.45048648  0.09259121  0.62944131 -0.19100129  0.73172382\n",
      "  0.21101264  0.58477661  0.75362265 -0.02704946  0.20830757  0.50347254\n",
      "  0.9619406   0.74906143  0.40031755  0.47883353  0.47290236 -0.23078233\n",
      "  0.07321858 -0.37623203  0.392866    0.33389255  0.7003727   0.49403429\n",
      "  0.07300793  0.03149279  0.48503426  0.44158843  0.72389897 -0.0049508\n",
      "  0.11577902  0.23012912  0.47963502  0.35799206  1.06327734  0.48403036\n",
      " -0.19579904  0.06352384  0.49054252 -0.15877746  0.78682379  0.87447322\n",
      "  0.56889009 -1.0785689   0.80433681 -0.44751179  0.60506978  0.76241081\n",
      "  0.11045816  0.53071225  0.61781389  0.38877271 -0.025316    0.86535439\n",
      " -0.16452232  0.15137685  0.20557305  0.7953392   1.08369651 -0.58227761\n",
      "  0.16112649  0.78136021  0.4055069   0.83521923  0.65089286  0.38250931\n",
      "  0.2427946  -0.20622713 -0.033507    0.33948769  0.75843688  0.29809867\n",
      "  0.30837147  0.27675485  0.16499751  0.01143022 -0.35106183 -0.45228708\n",
      "  0.29672161  0.24581661  0.77633375  0.03204526 -0.66777524  0.30398377]\n"
     ]
    }
   ],
   "source": [
    "options = {'c1': 0.5, 'c2': 0.3, 'w':0.9, 'k':2, 'p':2}\n",
    "\n",
    "dimensions = (n_inputs * n_hidden) + (n_hidden * n_classes) + 3*n_hidden + n_classes\n",
    "optimizer = ps.single.LocalBestPSO(n_particles=50, dimensions=dimensions, options=options)\n",
    "\n",
    "cost, pos = optimizer.optimize(f, iters=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Prediction\n",
    "def predict(pos):\n",
    "\n",
    "    logits = logits_f(pos)\n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.798"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predict(pos) == y).mean()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "artificial_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
