{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lP6JLo1tGNBg"
   },
   "source": [
    "# BIC - CW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWZyYmS_UE_L"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxkJoQBkUIHC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Import PySwarms as instructed by pyswarms webpage\n",
    "import pyswarms as ps\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1E0Q3aoKUCRX"
   },
   "source": [
    "## 1. Implement a multi-layer ANN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "#### Importing the dataset (Churn Modelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXUkhkMfU4wq"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "#### Encoding gender label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "#### Encoding geography label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zfEzkRVXIwF"
   },
   "source": [
    "### Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvdeScabXtlB"
   },
   "source": [
    "#### Initialising the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dtrScHxXQox"
   },
   "outputs": [],
   "source": [
    "n_inputs = 12\n",
    "n_hidden = 20\n",
    "n_classes = 2\n",
    "\n",
    "num_samples = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_function(p):\n",
    "\n",
    "    # Roll-back the weights and biases\n",
    "    W1 = p[0:240].reshape((n_inputs,n_hidden))\n",
    "    b1 = p[240:260].reshape((n_hidden,))\n",
    "    W2 = p[260:300].reshape((n_hidden,n_classes))\n",
    "    b2 = p[300:302].reshape((n_classes,))\n",
    "\n",
    "    # Perform forward propagation\n",
    "    z1 = X.dot(W1) + b1 # Pre-activation in Layer 1\n",
    "    a1 = np.tanh(z1.astype(float))     # Activation in Layer 1\n",
    "    logits = a1.dot(W2) + b2 # Pre-activation in Layer 2\n",
    "    return logits          # Logits for Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(params):\n",
    "    \"\"\"Forward propagation as objective function\n",
    "\n",
    "    This computes for the forward propagation of the neural network, as\n",
    "    well as the loss.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    params: np.ndarray\n",
    "        The dimensions should include an unrolled version of the\n",
    "        weights and biases.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The computed negative log-likelihood loss given the parameters\n",
    "    \"\"\"\n",
    "\n",
    "    logits = logits_function(params)\n",
    "\n",
    "    # Compute for the softmax of the logits\n",
    "    exp_scores = np.exp(logits)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "    # Compute for the negative log likelihood\n",
    "\n",
    "    corect_logprobs = -np.log(probs[range(num_samples), y])\n",
    "    loss = np.sum(corect_logprobs) / num_samples\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"Higher-level method to do forward_prop in the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    n_particles = x.shape[0]\n",
    "    j = [forward_prop(x[i]) for i in range(n_particles)]\n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-21 14:22:52,383 - pyswarms.single.local_best - INFO - Optimize for 500 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9, 'k': 2, 'p': 2}\n",
      "pyswarms.single.local_best: 100%|██████████|500/500, best_cost=0.489\n",
      "2020-11-21 14:24:36,260 - pyswarms.single.local_best - INFO - Optimization finished | best cost: 0.4888158120249897, best pos: [ 1.21482074  0.7881419   0.24926505  1.01981136  0.32132623  0.04507661\n",
      "  0.78399062  1.0131159   0.85831581  0.66539697  1.01260791  0.67842932\n",
      "  0.36851011  0.69377905  0.97822971  0.78624466  0.54362503  0.36663204\n",
      "  0.87754852  0.62848768  1.17873796  0.4686652   0.46787061  0.15989149\n",
      "  0.574404    0.75764287  0.59209293  0.43828596  0.22069491  0.85094184\n",
      "  0.49041101  0.53171188  0.79396976  0.82493611  0.30312517  0.66188883\n",
      "  0.4294386   0.56701081  0.60729776  0.58645197  0.09823742  0.63439127\n",
      "  1.03057175  0.47464705  0.27140323  1.08808715  0.37240363  0.39168362\n",
      "  0.34264138  1.1117389   0.03144129  0.04279156  0.15550617  0.42573821\n",
      "  0.74723878  0.50185613  0.21127756  0.1250924   0.72950396  0.02776294\n",
      "  0.55634585  1.27351293  1.02006733  0.78753233  1.17494605  0.8288964\n",
      "  0.59998543  0.96585151  0.38350117  0.67703772  0.46141486  0.64649205\n",
      "  0.46792701  0.29817993  0.40445499  1.46588749  0.57319915  0.15318694\n",
      "  0.2120848   0.9520282   0.58287641  0.24807628  0.99796768  1.57164145\n",
      "  0.72908463  0.6627001   1.13325251  0.6447711   0.4429205   0.82896842\n",
      "  0.63802397  0.96240809  0.70847828  0.89299522  0.51387994  0.93272739\n",
      "  0.42790107  0.24219988  0.64300874  0.07266814  0.78312426  1.33175667\n",
      "  0.70002352  0.85554685 -0.22243861  0.91185678  1.03369932  0.76830459\n",
      "  0.95409226  0.6116241   0.46669538  0.89557323  0.23689196  0.48979628\n",
      " -0.06737001  0.31782911  0.80592647  0.72915357  0.6764253   1.02975685\n",
      "  1.02562252  1.13710984  0.38014004  0.58780863  0.90672538  0.94977887\n",
      "  0.4181288   0.07797389  0.53557181  0.33795375  0.1704487   0.26632529\n",
      "  1.36674583  0.53930492  0.69915174  0.72020625 -0.00286858  0.66310148\n",
      "  1.216324    0.42183786 -0.11314229  1.24658494  0.37369155  0.83186287\n",
      "  0.81986948  0.52210684  0.62012322  0.91997797 -0.01030041 -0.08072953\n",
      "  0.13653044  0.83852668  0.77752637  0.67851753  0.75305437  0.86312252\n",
      "  1.18140519  0.3954386   0.39846535  0.43697553  0.80849777 -0.19456952\n",
      "  1.19519705  0.63113111  0.15282206  1.02828357  0.50758353  0.50980863\n",
      "  1.06733345  0.32643856  0.73150713  0.45970873  1.16012588  0.95297624\n",
      "  0.98263759  0.32893146  1.57813     0.50750386  0.31274531  0.84424425\n",
      "  0.54528006  0.37681691  0.31459757  0.36269532  0.47544093  0.32467785\n",
      "  0.85445073  0.0322926   1.11034255  0.63467885  0.5121337   0.03786987\n",
      "  0.28260732  0.39246264  0.65031991  0.30316059  0.59315103  1.35644061\n",
      "  0.42764156  0.11803323  0.28454188  0.69496328  0.34491105  0.30939963\n",
      "  0.06829589  0.55627822  0.30926647  1.1585271   0.80646116  0.57551497\n",
      "  0.7060797  -0.02302947 -0.38507175  0.08156493  0.26337094  0.55695155\n",
      "  0.30875268  0.73232538  0.70699872  1.08618524  0.28285748  0.02599689\n",
      "  0.5129411   0.84358601  0.80271843  0.93951693  0.35136774 -0.03140471\n",
      "  0.07639557  0.66238368  0.30558127 -0.00394408  0.86541765  1.40986493\n",
      "  0.70310772  0.32724251  0.93945806  0.64062232  0.19152005  0.64059811\n",
      "  0.84762373  0.29402909  0.25415514  0.30746724  0.20554935  0.78486184\n",
      "  0.4999613   0.88449828  0.42620036  0.48101076  0.30496656  0.50280055\n",
      "  0.39680545  0.55114358  0.41480955  0.84224571  0.24883459  0.37612176\n",
      "  0.65490128  0.44906073  0.8874365   0.84682156  0.4811076   0.60007666\n",
      "  0.49703339  1.92899144  0.50671296 -0.14194478  0.61861712  0.29160224\n",
      "  0.20287919  0.38336223  1.25661826  0.15714008  0.57848478  1.17162941\n",
      "  0.5020115   0.38467698  0.6481204   0.512002    0.88741604  0.33306502\n",
      "  1.05885482  0.63491696  0.9334943   1.27989584  1.0247315   1.23625458\n",
      "  1.04809835  0.50171847  0.93137047  0.73861254  1.31865431  1.02718045\n",
      "  0.74746761  0.22379755  0.11672447  0.26351767  1.03058926  0.63800689\n",
      " -0.36766224  0.73348437  0.29892716  0.53932109 -0.18867546  0.76218412\n",
      " -0.01015846  0.32126667  0.0853598   0.50735398  0.30506004  0.54889987\n",
      "  0.73732449  0.98278039  1.06852046  0.12870601 -0.03871906  0.39563596\n",
      "  1.13404527  0.54294392  0.42746547  0.35450761  0.61569219  1.00608192\n",
      "  0.31663667  0.6868677   0.05432917  0.19432369  1.19768767  0.59051295\n",
      "  1.06853023 -0.01242287  0.32468334  0.49359945  1.01944194  0.49072455\n",
      "  0.11865164  0.70527605  0.37964752  0.73756128  0.832172    0.60033525]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 43s, sys: 766 ms, total: 1min 43s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initialize swarm\n",
    "options = {'c1': 0.5, 'c2': 0.3, 'w':0.9, 'k':2, 'p':2}\n",
    "\n",
    "# Call instance of PSO\n",
    "dimensions = (n_inputs * n_hidden) + (n_hidden * n_classes) + 3*n_hidden + n_classes\n",
    "optimizer = ps.single.LocalBestPSO(n_particles=50, dimensions=dimensions, options=options)\n",
    "\n",
    "# Perform optimization\n",
    "cost, pos = optimizer.optimize(f, iters=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(pos):\n",
    "    \"\"\"\n",
    "    Use the trained weights to perform class predictions.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    pos: numpy.ndarray\n",
    "        Position matrix found by the swarm. Will be rolled\n",
    "        into weights and biases.\n",
    "    \"\"\"\n",
    "    logits = logits_function(pos)\n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3039b0186a68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pos' is not defined"
     ]
    }
   ],
   "source": [
    "(predict(pos) == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Neurons and Layers Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = int(input(\"Enter number of neurons: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "n = int(input(\"Enter number of layers (1-5): \"))\n",
    "if n < 6 and n > 0:\n",
    "    for i in range (0, n):\n",
    "        print(\"Hyperbolic tangent layer must run every time.\")\n",
    "        print(\"Available activation functions: linear, sigmoid, gaussian, cosine, null\")\n",
    "        layer = input(\"Enter name of desired activation function: \")\n",
    "    \n",
    "        layers.append(layer)    \n",
    "else:\n",
    "    print(\"Wrong number of layers entered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rP6urV6SX7kS"
   },
   "source": [
    "### Adding the input layer and the first hidden layer with linear AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bppGycBXYCQr"
   },
   "outputs": [],
   "source": [
    "if \"linear\" in layers:\n",
    "    ann.add(tf.keras.layers.Dense(units=neurons, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the second hidden layer with Sigmoid AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JneR0u0sYRTd"
   },
   "outputs": [],
   "source": [
    "if \"sigmoid\" in layers:\n",
    "    ann.add(tf.keras.layers.Dense(units=neurons, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the third hidden layer with Gaussian AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"gaussian\" in layers:\n",
    "    ann.add(tf.keras.layers.Dense(units=neurons, activation='gaussian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the fourth hidden layer with Cosine AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"cosine\" in layers:\n",
    "    ann.add(tf.keras.layers.Dense(units=neurons, activation='cosine'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the fifth hidden layer with Null AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"null\" in layers:\n",
    "    ann.add(tf.keras.layers.Dense(units=neurons, activation='nullact'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyNEe6RXYcU4"
   },
   "source": [
    "### Adding the output layer with Hyperbolic Tangent AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3x41RBYfvY"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='tanh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT4u2S1_Y4WG"
   },
   "source": [
    "## Part 3 - Training the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GWlJChhY_ZI"
   },
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG3RrwDXZEaS"
   },
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QR_G5u7ZLSM"
   },
   "source": [
    "### Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG3RrwDXZEaS"
   },
   "outputs": [],
   "source": [
    "def forward_prop(params):\n",
    "    \n",
    "    for x_train, y_train in dataset:\n",
    "        logits = ann(params)\n",
    "    \n",
    "    exp_scores = np.exp(logits)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "    # Compute for the negative log likelihood\n",
    "\n",
    "    corect_logprobs = -np.log(probs[range(num_samples), y])\n",
    "    loss = np.sum(corect_logprobs) / num_samples\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    n_particles = x.shape[0]\n",
    "    print(n_particles)\n",
    "    j = [forward_prop(x[i]) for i in range(n_particles)]\n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize swarm\n",
    "options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
    "\n",
    "# Call instance of PSO\n",
    "dimensions = 54\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=100, dimensions=dimensions, options=options)\n",
    "\n",
    "# Perform optimization\n",
    "cost, pos = optimizer.optimize(f, iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nHZ-LKv_ZRb3",
    "outputId": "718cc4b0-b5aa-40f0-9b20-d3d31730a531"
   },
   "outputs": [],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJj5k2MxZga3"
   },
   "source": [
    "## Part 4 - Making the predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84QFoqGYeXHL"
   },
   "source": [
    "### Predicting the result of a single observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZhU1LTgPg-kH"
   },
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2d8IoCCkeWGL",
    "outputId": "957f3970-e197-4c3b-a150-7f69dc567f5d"
   },
   "outputs": [],
   "source": [
    "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7yx47jPZt11"
   },
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "nIyEeQdRZwgs",
    "outputId": "82330ba8-9bdc-4fd1-d3cf-b6d78ee7c2a3"
   },
   "outputs": [],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0oyfLWoaEGw"
   },
   "source": [
    "### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ci6K_r6LaF6P",
    "outputId": "4d854e9e-22d5-432f-f6e5-a102fe3ae0bd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "artificial_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
